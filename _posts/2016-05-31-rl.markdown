---
layout: post
comments: true
title:  "A visit of Dimitri Bertsekas"
excerpt: "I had a chance of visiting Dimitri Bertsekas July 19th 2017 at MIT. This summarizes the topics we discussed."
date:   2017-07-19 19:00:00
mathjax: false
---

Dimitri Bertsekas is a well known professor at CSAIL at MIT. His work on neuro-dynamic programming establishes a theoretical foundation for reinforcement learning. He is an IEEE fellow and McAfee Professor at MIT. His Google scholar citation is 82,419 (checked just today). We met briefly in 2008 at ICML in Helsinki. He didn't change much. Sitting in his office, I feel so humble surrounded by the books he has written. 

Dimitri said he spent 20 years understanding Tetris (starting with the lambda-policy iteration paper with Ioffe). Why TDlambda (all lambda) failed horribly. So far he still don't have a good understanding. His take is that Tetris has lots of variance and lots of simulations are required. He is aware of the Cross Entropy work by Istanvan Szityu and Schuer (sorry couldn't recall the exact name), but these work didn't explain why. He showed two papers by Schuer and said if I find out something, he would be happy to know. 

about Deep Reinforcement Learning, Dimitri doesn't think there is any interesting questions can be asked from theoretical perspective.  I meant to see if any interesting things can be discussed (I prepared a few), but he doesn't seem to be interested. His take is that neural network with reinforcement learning, discussions and efforts have been tried in approximate dynamic programming and reinforcement learning. Research questions are the same whether  it's 3 layers or 3000 layers. I seem to buy this. Does this mean my intended questions are not meaningful? Indeed, it seems true. Doesn't seem the number of layers in the neural network bring interesting, unique perspective. 

on preconditioning TD algorithm (my ICML paper), he asked whether the adaptive step-size is diminishing eventually. Unfortunately I don't quite remember but I will check. He said he is sure some nice thing can be proved about the step-size. He actually had a new (4th) edition of "Dynamic Programming and Optimal Control" coming out just a few months. I felt so honored when he showed my paper in the book's reference. He also kindly gave me the two-volume books and signed his name!

on self-driving cars. He said he heard about the project when he started his Ph.D! when was that? probably in 60s. He said at the time two major applications were proposed. One is the data networks and the other is just the self-driving car. However data networks took off quickly and self-driving cars had been left kinda of dream until a few years ago. He said Reinforcement Learning "owns" self-driving cars. 

on Model Predictive Controller (MPC). I mentioned MPC is widely used in self-driving car for planning, but people is not aware it's a RL algorithm. He said MPC people are learning RL and trying to learn a model from data. His take is that MPC assumes a good, known model. Learning from online data to drive well seems very hard. At least he is not sure how. He mentioned there is a guy "Alberto Bemporad" an expert on MPC is thinking to use neural network to learn the model, although he hasn't done it yet because he is not sure how. 

on Proximal Algorithms. He said TD is a proximal algorithm. I asked whether proximal algorithms can be used for L1 constraint. He said for TD will need L2. 

on Pseudo MDPs. Following the proximal algorithm, I mentioned Csaba, Bernardo and Xinhua and me were working on a pseudo MDP paper, which we used L1 constraint to learn an approximate operator for a given MDP. He asked the paper. I said you can just check Csaba's homepage. He said, I'd use Google scholar because I cannot spell his name. Then he typed "Szepesvari" in the browser :) He: what's the connection to state aggregation? I said, state aggregation, the states in the same cluster has the same representation. He corrected me: only true when in the abstract MDP. I agree. He is interested in the work and said he will follow up.

Finally looking at the bookshelf, I can see most of them are written by him. I asked: "which book is your most proud of?" He thought a while then smiled happily "there is not a book that I write I am not proud of so far. "
